{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement:\n",
    "- numpy 1.19.5\n",
    "- tensorflow 2.5.0\n",
    "- tensorflow_privacy 0.6.1\n",
    "- sklearn 0.24.2\n",
    "\n",
    "Before performing the experiments, you need to fit the **pickle_file**(path for tabular QMNIST data) according to your own PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iYdgdZMocHNk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import random as python_random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuMDw0xmAH-d"
   },
   "source": [
    "# Load QMNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOBOLaM6ghKD",
    "outputId": "4191ad8b-6f65-4ad6-87e6-fc1d695cb81a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "pickle_file = '/home/jiangnan/Desktop/ppml-workshop/data/QMNIST_tabular_ppml.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  x_defender = pickle_data['x_defender']\n",
    "  x_reserve = pickle_data['x_reserve']\n",
    "  y_defender = pickle_data['y_defender']\n",
    "  y_reserve = pickle_data['y_reserve']\n",
    "  del pickle_data\n",
    "print('Data loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qW1n24bvs6nP"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "y_defender = y_defender[:,0]\n",
    "y_reserve = y_reserve[:,0]\n",
    "\n",
    "#y_defender = np.expand_dims(y_defender,axis=1)\n",
    "#y_reserve = np.expand_dims(y_reserve,axis=1)\n",
    "\n",
    "#y_defender = tf.keras.utils.to_categorical(y_defender, num_classes=NUM_CLASSES)\n",
    "#y_reserve = tf.keras.utils.to_categorical(y_reserve, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TfaWzhkATJq"
   },
   "source": [
    "# Defender model $M_D$\n",
    "\n",
    "import the defender model which need to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WjQgTR5vcerZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def defender_model_fn(data_in):\n",
    "    \"\"\"The architecture of the defender (victim) model.\n",
    "    The attack is white-box, hence the attacker is assumed to know this architecture too.\"\"\"\n",
    "    random_seeds = random.sample(range(0,100), 2)\n",
    "    np.random.seed(random_seeds[0])\n",
    "    python_random.seed(random_seeds[1])\n",
    "    \n",
    "    model = KDTree(data_in)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# if random_select, randomly extract two points from both defender & reserve dataset, and repeat for n_extract times\n",
    "random_select = True\n",
    "n_extract = 100\n",
    "\n",
    "#if given_index, the attack will put the two left out points back to their original place\n",
    "given_index = False\n",
    "n_sample = 6  #( 7 for 48 - 3200, 8 for 48 - 6400, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZg1y29Y_-bp"
   },
   "source": [
    "# Oracle attack model $M_A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "utePp7mWuXNy"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mock_defender_models(defender, data_in, data_out, n_records = 48, random_select = True, n_extract = 100, given_index = False):\n",
    "    \n",
    "    similarities_in = []\n",
    "    similarities_out = []\n",
    "    \n",
    "    number_loop = 0\n",
    "    \n",
    "    if random_select == True:\n",
    "        number_loop = n_extract\n",
    "    else:\n",
    "        number_loop = data_in[0].shape[0]\n",
    "        \n",
    "    for i in tqdm(range(number_loop)):\n",
    "\n",
    "        if random_select == True:\n",
    "            index = random.randint(0,n_records-1)\n",
    "        else:\n",
    "            index = i\n",
    "\n",
    "        evaluation_data_in = data_in[0][index]\n",
    "        evaluation_label_in = data_in[1][index]\n",
    "\n",
    "        evaluation_data_out = data_out[0][index]\n",
    "        evaluation_label_out = data_out[1][index]\n",
    "\n",
    "        evaluation_data = np.array([evaluation_data_in, evaluation_data_out])\n",
    "        evaluation_label = np.array([evaluation_label_in, evaluation_label_out])\n",
    "\n",
    "        evaluation = evaluation_data, evaluation_label\n",
    "\n",
    "\n",
    "        attack_train_data_in = np.delete(data_in[0], index, axis=0)\n",
    "        attack_train_label_in = np.delete(data_in[1], index, axis=0)\n",
    "\n",
    "        attack_in = attack_train_data_in, attack_train_label_in\n",
    "\n",
    "\n",
    "        attack_train_data_out = np.delete(data_out[0], index, axis=0)\n",
    "        attack_train_label_out = np.delete(data_out[1], index, axis=0)\n",
    "\n",
    "        attack_out = attack_train_data_out, attack_train_label_out\n",
    "\n",
    "        predict = defender_model.query(attack_in[0],k=1)\n",
    "        \n",
    "        if given_index == True:\n",
    "\n",
    "            attack_in_plus_one_in = np.insert(attack_in[0], index, evaluation[0][0].reshape(1,attack_in[0].shape[1]), axis=0), np.insert(attack_in[1], index, evaluation[1][0], axis=0)\n",
    "            attack_in_plus_one_out = np.insert(attack_in[0], index, evaluation[0][1].reshape(1,attack_in[0].shape[1]), axis=0), np.insert(attack_in[1], index, evaluation[1][1], axis=0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            attack_in_plus_one_in = np.vstack((evaluation[0][0].reshape(1,attack_in[0].shape[1]),attack_in[0])), np.hstack(( evaluation[1][0],attack_in[1]))\n",
    "            attack_in_plus_one_out = np.vstack((evaluation[0][1].reshape(1,attack_in[0].shape[1]),attack_in[0])), np.hstack(( evaluation[1][1],attack_in[1]))\n",
    "\n",
    "        \n",
    "        M_cD_in = defender_model_fn(attack_in_plus_one_in[0])\n",
    "        M_cD_out = defender_model_fn(attack_in_plus_one_out[0])\n",
    "        \n",
    "        M_cD_in_predict = M_cD_in.query(attack_in[0])\n",
    "        M_cD_out_predict = M_cD_out.query(attack_in[0])\n",
    "\n",
    "        similarity_in = np.mean(np.linalg.norm(M_cD_in_predict[1]-predict[1], axis=1))\n",
    "        similarity_out = np.mean(np.linalg.norm(M_cD_out_predict[1]-predict[1], axis=1))\n",
    "\n",
    "        similarities_in.append(similarity_in)\n",
    "        similarities_out.append(similarity_out)\n",
    "    \n",
    "    return similarities_in, similarities_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:03<00:00,  1.58it/s]\n",
      "100%|██████████| 100/100 [00:59<00:00,  1.67it/s]\n",
      "100%|██████████| 100/100 [00:59<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracy_out_all = []\n",
    "\n",
    "similarities_in_all = []\n",
    "similarities_out_all = []\n",
    "\n",
    "n_records = 1600\n",
    "n_trials = 3\n",
    "\n",
    "for i in range(n_trials):\n",
    "    \n",
    "    \n",
    "    random_indexes = random.sample(range(0,200000), n_records)\n",
    "    data_in = x_defender[random_indexes], y_defender[random_indexes]\n",
    "    data_out = x_reserve[random_indexes], y_reserve[random_indexes]\n",
    "    defender_model = defender_model_fn(data_in[0])\n",
    "    \n",
    "    dist, ind= defender_model.query(data_out[0],k=1)\n",
    "    \n",
    "    predict = data_in[1][ind]\n",
    "    \n",
    "    acc = accuracy_score(data_out[1], predict)\n",
    "    \n",
    "    accuracy_out_all.append(acc)\n",
    "    \n",
    "    similarities_in, similarities_out = create_mock_defender_models(defender = defender_model,\n",
    "                                                                    data_in = data_in,\n",
    "                                                                    data_out = data_out,\n",
    "                                                                    n_records = 1600,\n",
    "                                                                    random_select = random_select,\n",
    "                                                                    n_extract = n_extract,\n",
    "                                                                    given_index = given_index)\n",
    "    \n",
    "    similarities_in_all.append(similarities_in)\n",
    "    similarities_out_all.append(similarities_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_all = (10*np.array(accuracy_out_all)-1)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488425925925925"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(utility_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 52791.74it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 37681.29it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 58514.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute the privacy values by comparing all model pairs\n",
    "\n",
    "privacy_all = []\n",
    "variance_all = []\n",
    "sigma_error_all = []\n",
    "\n",
    "for i in range(len(similarities_in_all)):\n",
    "    \n",
    "    similarities_in = similarities_in_all[i]\n",
    "    similarities_out = similarities_out_all[i]\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for j in tqdm(range(len(similarities_in))):\n",
    "        for k in range(len(similarities_out)):\n",
    "\n",
    "            if similarities_in[j] <= similarities_out[k]:\n",
    "                results.append(1)\n",
    "            else:\n",
    "                results.append(0)\n",
    "\n",
    "    n = len(results)\n",
    "    p = 1-np.sum(results)/n\n",
    "\n",
    "    privacy = min(2*p,1)\n",
    "    variance = 2*p*(1-p)/n\n",
    "    sigma_error = 2*np.sqrt(p*(1-p)/n)\n",
    "    \n",
    "    privacy_all.append(privacy)\n",
    "    variance_all.append(variance)\n",
    "    sigma_error_all.append(sigma_error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9124\n",
      "4.9616226666666665e-05\n",
      "0.009961548675457543\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(privacy_all))\n",
    "print(np.mean(variance_all))\n",
    "print(np.mean(sigma_error_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9616226666666665e-05"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(variance_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009961548675457543"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sigma_error_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Easy_NewMIA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
