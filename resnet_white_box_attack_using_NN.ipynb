{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  \n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import collections\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_with_NN_results_dir = \"attack_with_NN_resnet50_feature_shapes\"\n",
    "if not os.path.exists(attack_with_NN_results_dir):\n",
    "    os.makedirs(attack_with_NN_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 3, 224, 224]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1]) torch.int64\n",
      "<class 'torch.Tensor'> torch.Size([1, 10]) torch.float32 tensor([[ 0.3862,  0.4995,  0.4248, -0.3419,  0.4738,  0.2802, -0.2655,  0.4078,\n",
      "         -1.5438,  0.4691]], grad_fn=<AddmmBackward>)\n",
      "<class 'torch.Tensor'> torch.Size([]) torch.float32 2.8573009967803955\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "def get_transform(device):\n",
    "    \"\"\"\n",
    "    Input: numpy.ndarray, shape = (28, 28), uint8\n",
    "    Output: torch.Tensor (cpu or cuda), torch.Size([1, 3, 224, 224]), torch.float32\n",
    "    \"\"\"\n",
    "    transform = torchvision.transforms.Compose(\n",
    "        [lambda x: Image.fromarray(x),\n",
    "         lambda x: x.convert(\"RGB\") if x.mode == \"L\" else x,\n",
    "         torchvision.transforms.Resize([224, 224]),\n",
    "         torchvision.transforms.ToTensor(),\n",
    "         torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                          std=[0.229, 0.224, 0.225]),\n",
    "         lambda x: torch.unsqueeze(x, 0),\n",
    "         lambda x: x.to(device)],\n",
    "    )\n",
    "    return transform\n",
    "\n",
    "# preprocessor\n",
    "transform = get_transform(device)\n",
    "\n",
    "# define resnet50\n",
    "model = models.resnet50(pretrained=False)\n",
    "fc_in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_in_features, 10)\n",
    "\n",
    "# input\n",
    "random_input = np.random.randint(low=0, high=256, size=(28, 28), dtype=np.uint8)\n",
    "random_input = transform(random_input)\n",
    "print(type(random_input), random_input.shape, random_input.dtype)\n",
    "\n",
    "y = torch.from_numpy(np.random.randint(low=0, high=10, size=(1), dtype=np.int64))\n",
    "print(type(y), y.shape, y.dtype)\n",
    "\n",
    "# forward pass\n",
    "model.train()\n",
    "output = model(random_input)\n",
    "print(type(output), output.shape, output.dtype, output)\n",
    "\n",
    "# backward pass\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(output, y)\n",
    "loss.backward()\n",
    "print(type(loss), loss.shape, loss.dtype, loss.item())\n",
    "\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.nn.modules.conv.Conv2d,\n",
       " torch.nn.modules.batchnorm.BatchNorm2d,\n",
       " torchvision.models.resnet.ResNet,\n",
       " torch.nn.modules.container.Sequential,\n",
       " torch.nn.modules.linear.Linear,\n",
       " torchvision.models.resnet.Bottleneck,\n",
       " torch.nn.modules.activation.ReLU,\n",
       " torch.nn.modules.pooling.MaxPool2d,\n",
       " torch.nn.modules.pooling.AdaptiveAvgPool2d]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = []\n",
    "for name, layer in model.named_modules():\n",
    "    tmp.append(type(layer))\n",
    "tmp = list(set(tmp))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 conv1\n",
      "2 layer1.0.conv1\n",
      "3 layer1.0.conv2\n",
      "4 layer1.0.conv3\n",
      "5 layer1.0.downsample.0\n",
      "6 layer1.1.conv1\n",
      "7 layer1.1.conv2\n",
      "8 layer1.1.conv3\n",
      "9 layer1.2.conv1\n",
      "10 layer1.2.conv2\n",
      "11 layer1.2.conv3\n",
      "12 layer2.0.conv1\n",
      "13 layer2.0.conv2\n",
      "14 layer2.0.conv3\n",
      "15 layer2.0.downsample.0\n",
      "16 layer2.1.conv1\n",
      "17 layer2.1.conv2\n",
      "18 layer2.1.conv3\n",
      "19 layer2.2.conv1\n",
      "20 layer2.2.conv2\n",
      "21 layer2.2.conv3\n",
      "22 layer2.3.conv1\n",
      "23 layer2.3.conv2\n",
      "24 layer2.3.conv3\n",
      "25 layer3.0.conv1\n",
      "26 layer3.0.conv2\n",
      "27 layer3.0.conv3\n",
      "28 layer3.0.downsample.0\n",
      "29 layer3.1.conv1\n",
      "30 layer3.1.conv2\n",
      "31 layer3.1.conv3\n",
      "32 layer3.2.conv1\n",
      "33 layer3.2.conv2\n",
      "34 layer3.2.conv3\n",
      "35 layer3.3.conv1\n",
      "36 layer3.3.conv2\n",
      "37 layer3.3.conv3\n",
      "38 layer3.4.conv1\n",
      "39 layer3.4.conv2\n",
      "40 layer3.4.conv3\n",
      "41 layer3.5.conv1\n",
      "42 layer3.5.conv2\n",
      "43 layer3.5.conv3\n",
      "44 layer4.0.conv1\n",
      "45 layer4.0.conv2\n",
      "46 layer4.0.conv3\n",
      "47 layer4.0.downsample.0\n",
      "48 layer4.1.conv1\n",
      "49 layer4.1.conv2\n",
      "50 layer4.1.conv3\n",
      "51 layer4.2.conv1\n",
      "52 layer4.2.conv2\n",
      "53 layer4.2.conv3\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "        cnt += 1\n",
    "        print(cnt, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 relu\n",
      "2 layer1.0.relu\n",
      "3 layer1.1.relu\n",
      "4 layer1.2.relu\n",
      "5 layer2.0.relu\n",
      "6 layer2.1.relu\n",
      "7 layer2.2.relu\n",
      "8 layer2.3.relu\n",
      "9 layer3.0.relu\n",
      "10 layer3.1.relu\n",
      "11 layer3.2.relu\n",
      "12 layer3.3.relu\n",
      "13 layer3.4.relu\n",
      "14 layer3.5.relu\n",
      "15 layer4.0.relu\n",
      "16 layer4.1.relu\n",
      "17 layer4.2.relu\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.activation.ReLU):\n",
    "        cnt += 1\n",
    "        print(cnt, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fc\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.linear.Linear):\n",
    "        cnt += 1\n",
    "        print(cnt, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 53\n",
      "<class 'torch.Tensor'> torch.Size([802816]) 802816\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([802816]) 802816\n",
      "<class 'torch.Tensor'> torch.Size([802816]) 802816\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([802816]) 802816\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([802816]) 802816\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([50176]) 50176\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([25088]) 25088\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([25088]) 25088\n",
      "<class 'torch.Tensor'> torch.Size([25088]) 25088\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([25088]) 25088\n",
      "<class 'torch.Tensor'> torch.Size([25088]) 25088\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "11113984\n"
     ]
    }
   ],
   "source": [
    "# define resnet50\n",
    "model = models.resnet50(pretrained=False)\n",
    "fc_in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_in_features, 10)\n",
    "\n",
    "# hooks for hidden layer intermediate features\n",
    "hidden_layer_features = {}\n",
    "def get_hidden_layer_features(name):\n",
    "    def hook(model, input, output):\n",
    "        hidden_layer_features[name] = output.detach().view(-1)\n",
    "    return hook\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "        layer.register_forward_hook(get_hidden_layer_features(name))\n",
    "        \n",
    "\n",
    "random_input = np.random.randint(low=0, high=256, size=(28, 28), dtype=np.uint8)\n",
    "random_input = transform(random_input)\n",
    "y = torch.from_numpy(np.random.randint(low=0, high=10, size=(1), dtype=np.int64))\n",
    "output = model(random_input)\n",
    "\n",
    "print(type(hidden_layer_features), len(hidden_layer_features))\n",
    "for k in hidden_layer_features.keys():\n",
    "    print(type(hidden_layer_features[k]), hidden_layer_features[k].shape, len(hidden_layer_features[k]))\n",
    "    \n",
    "total = 0\n",
    "for k in hidden_layer_features.keys():\n",
    "    total += len(hidden_layer_features[k])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 17\n",
      "<class 'torch.Tensor'> torch.Size([1, 64, 112, 112]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 256, 56, 56]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 256, 56, 56]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 256, 56, 56]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 512, 28, 28]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 512, 28, 28]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 512, 28, 28]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 512, 28, 28]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 1024, 14, 14]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 1024, 14, 14]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 1024, 14, 14]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 1024, 14, 14]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 1024, 14, 14]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 1024, 14, 14]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 2048, 7, 7]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 2048, 7, 7]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1, 2048, 7, 7]) torch.float32\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# define resnet50\n",
    "model = models.resnet50(pretrained=False)\n",
    "fc_in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_in_features, 10)\n",
    "\n",
    "# hooks for hidden layer intermediate features\n",
    "hidden_layer_features = {}\n",
    "def get_hidden_layer_features(name):\n",
    "    def hook(model, input, output):\n",
    "        hidden_layer_features[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.activation.ReLU):\n",
    "        layer.register_forward_hook(get_hidden_layer_features(name))\n",
    "        \n",
    "\n",
    "random_input = np.random.randint(low=0, high=256, size=(28, 28), dtype=np.uint8)\n",
    "random_input = transform(random_input)\n",
    "y = torch.from_numpy(np.random.randint(low=0, high=10, size=(1), dtype=np.int64))\n",
    "output = model(random_input)\n",
    "\n",
    "print(type(hidden_layer_features), len(hidden_layer_features))\n",
    "for k in hidden_layer_features.keys():\n",
    "    print(type(hidden_layer_features[k]), hidden_layer_features[k].shape, hidden_layer_features[k].dtype)\n",
    "    \n",
    "total = 0\n",
    "for k in hidden_layer_features.keys():\n",
    "    total += len(hidden_layer_features[k])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 17\n",
      "<class 'torch.Tensor'> torch.Size([802816]) 802816\n",
      "<class 'torch.Tensor'> torch.Size([802816]) 802816\n",
      "<class 'torch.Tensor'> torch.Size([802816]) 802816\n",
      "<class 'torch.Tensor'> torch.Size([802816]) 802816\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([401408]) 401408\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([200704]) 200704\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "<class 'torch.Tensor'> torch.Size([100352]) 100352\n",
      "6322176\n"
     ]
    }
   ],
   "source": [
    "# define resnet50\n",
    "model = models.resnet50(pretrained=False)\n",
    "fc_in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_in_features, 10)\n",
    "\n",
    "# hooks for hidden layer intermediate features\n",
    "hidden_layer_features = {}\n",
    "def get_hidden_layer_features(name):\n",
    "    def hook(model, input, output):\n",
    "        hidden_layer_features[name] = output.detach().view(-1)\n",
    "    return hook\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.activation.ReLU):\n",
    "        layer.register_forward_hook(get_hidden_layer_features(name))\n",
    "        \n",
    "\n",
    "random_input = np.random.randint(low=0, high=256, size=(28, 28), dtype=np.uint8)\n",
    "random_input = transform(random_input)\n",
    "y = torch.from_numpy(np.random.randint(low=0, high=10, size=(1), dtype=np.int64))\n",
    "output = model(random_input)\n",
    "\n",
    "print(type(hidden_layer_features), len(hidden_layer_features))\n",
    "for k in hidden_layer_features.keys():\n",
    "    print(type(hidden_layer_features[k]), hidden_layer_features[k].shape, len(hidden_layer_features[k]))\n",
    "    \n",
    "total = 0\n",
    "for k in hidden_layer_features.keys():\n",
    "    total += len(hidden_layer_features[k])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 53\n",
      "conv1 <class 'torch.Tensor'> torch.Size([64, 112, 112]) torch.float32\n",
      "layer1.0.conv1 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.0.conv2 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.0.conv3 <class 'torch.Tensor'> torch.Size([256, 56, 56]) torch.float32\n",
      "layer1.0.downsample.0 <class 'torch.Tensor'> torch.Size([256, 56, 56]) torch.float32\n",
      "layer1.1.conv1 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.1.conv2 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.1.conv3 <class 'torch.Tensor'> torch.Size([256, 56, 56]) torch.float32\n",
      "layer1.2.conv1 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.2.conv2 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.2.conv3 <class 'torch.Tensor'> torch.Size([256, 56, 56]) torch.float32\n",
      "layer2.0.conv1 <class 'torch.Tensor'> torch.Size([128, 56, 56]) torch.float32\n",
      "layer2.0.conv2 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.0.conv3 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer2.0.downsample.0 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer2.1.conv1 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.1.conv2 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.1.conv3 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer2.2.conv1 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.2.conv2 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.2.conv3 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer2.3.conv1 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.3.conv2 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.3.conv3 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer3.0.conv1 <class 'torch.Tensor'> torch.Size([256, 28, 28]) torch.float32\n",
      "layer3.0.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.0.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.0.downsample.0 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.1.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.1.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.1.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.2.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.2.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.2.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.3.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.3.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.3.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.4.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.4.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.4.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.5.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.5.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.5.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer4.0.conv1 <class 'torch.Tensor'> torch.Size([512, 14, 14]) torch.float32\n",
      "layer4.0.conv2 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.0.conv3 <class 'torch.Tensor'> torch.Size([2048, 7, 7]) torch.float32\n",
      "layer4.0.downsample.0 <class 'torch.Tensor'> torch.Size([2048, 7, 7]) torch.float32\n",
      "layer4.1.conv1 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.1.conv2 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.1.conv3 <class 'torch.Tensor'> torch.Size([2048, 7, 7]) torch.float32\n",
      "layer4.2.conv1 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.2.conv2 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.2.conv3 <class 'torch.Tensor'> torch.Size([2048, 7, 7]) torch.float32\n",
      "\n",
      "26560\n",
      "\n",
      "OrderedDict([('conv1', [64, 112, 112]), ('layer1.0.conv1', [64, 56, 56]), ('layer1.0.conv2', [64, 56, 56]), ('layer1.0.conv3', [256, 56, 56]), ('layer1.0.downsample.0', [256, 56, 56]), ('layer1.1.conv1', [64, 56, 56]), ('layer1.1.conv2', [64, 56, 56]), ('layer1.1.conv3', [256, 56, 56]), ('layer1.2.conv1', [64, 56, 56]), ('layer1.2.conv2', [64, 56, 56]), ('layer1.2.conv3', [256, 56, 56]), ('layer2.0.conv1', [128, 56, 56]), ('layer2.0.conv2', [128, 28, 28]), ('layer2.0.conv3', [512, 28, 28]), ('layer2.0.downsample.0', [512, 28, 28]), ('layer2.1.conv1', [128, 28, 28]), ('layer2.1.conv2', [128, 28, 28]), ('layer2.1.conv3', [512, 28, 28]), ('layer2.2.conv1', [128, 28, 28]), ('layer2.2.conv2', [128, 28, 28]), ('layer2.2.conv3', [512, 28, 28]), ('layer2.3.conv1', [128, 28, 28]), ('layer2.3.conv2', [128, 28, 28]), ('layer2.3.conv3', [512, 28, 28]), ('layer3.0.conv1', [256, 28, 28]), ('layer3.0.conv2', [256, 14, 14]), ('layer3.0.conv3', [1024, 14, 14]), ('layer3.0.downsample.0', [1024, 14, 14]), ('layer3.1.conv1', [256, 14, 14]), ('layer3.1.conv2', [256, 14, 14]), ('layer3.1.conv3', [1024, 14, 14]), ('layer3.2.conv1', [256, 14, 14]), ('layer3.2.conv2', [256, 14, 14]), ('layer3.2.conv3', [1024, 14, 14]), ('layer3.3.conv1', [256, 14, 14]), ('layer3.3.conv2', [256, 14, 14]), ('layer3.3.conv3', [1024, 14, 14]), ('layer3.4.conv1', [256, 14, 14]), ('layer3.4.conv2', [256, 14, 14]), ('layer3.4.conv3', [1024, 14, 14]), ('layer3.5.conv1', [256, 14, 14]), ('layer3.5.conv2', [256, 14, 14]), ('layer3.5.conv3', [1024, 14, 14]), ('layer4.0.conv1', [512, 14, 14]), ('layer4.0.conv2', [512, 7, 7]), ('layer4.0.conv3', [2048, 7, 7]), ('layer4.0.downsample.0', [2048, 7, 7]), ('layer4.1.conv1', [512, 7, 7]), ('layer4.1.conv2', [512, 7, 7]), ('layer4.1.conv3', [2048, 7, 7]), ('layer4.2.conv1', [512, 7, 7]), ('layer4.2.conv2', [512, 7, 7]), ('layer4.2.conv3', [2048, 7, 7])])\n"
     ]
    }
   ],
   "source": [
    "# define resnet50\n",
    "model = models.resnet50(pretrained=False)\n",
    "fc_in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_in_features, 10)\n",
    "\n",
    "# hooks for hidden layer intermediate features\n",
    "hidden_layer_features = {}\n",
    "def get_hidden_layer_features(name):\n",
    "    def hook(model, input, output):\n",
    "        hidden_layer_features[name] = output.detach().squeeze(dim=0)\n",
    "    return hook\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "        layer.register_forward_hook(get_hidden_layer_features(name))\n",
    "        \n",
    "\n",
    "random_input = np.random.randint(low=0, high=256, size=(28, 28), dtype=np.uint8)\n",
    "random_input = transform(random_input)\n",
    "y = torch.from_numpy(np.random.randint(low=0, high=10, size=(1), dtype=np.int64))\n",
    "output = model(random_input)\n",
    "\n",
    "hidden_layer_features_shape = collections.OrderedDict()\n",
    "print(type(hidden_layer_features), len(hidden_layer_features))\n",
    "for k in hidden_layer_features.keys():\n",
    "    print(k, type(hidden_layer_features[k]), hidden_layer_features[k].shape, hidden_layer_features[k].dtype)\n",
    "    hidden_layer_features_shape[k] = np.array(hidden_layer_features[k].shape).tolist()\n",
    "    \n",
    "print()\n",
    "total = 0\n",
    "for k in hidden_layer_features.keys():\n",
    "    total += len(hidden_layer_features[k])\n",
    "print(total)\n",
    "print()\n",
    "\n",
    "print(hidden_layer_features_shape)\n",
    "with open(os.path.join(attack_with_NN_results_dir, \"hidden_layer_features_shape.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(hidden_layer_features_shape, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([]) torch.float32 2.6498537063598633\n",
      "conv1 torch.Size([64, 3, 7, 7]) torch.float32\n",
      "layer1.0.conv1 torch.Size([64, 64, 1, 1]) torch.float32\n",
      "layer1.0.conv2 torch.Size([64, 64, 3, 3]) torch.float32\n",
      "layer1.0.conv3 torch.Size([256, 64, 1, 1]) torch.float32\n",
      "layer1.0.downsample.0 torch.Size([256, 64, 1, 1]) torch.float32\n",
      "layer1.1.conv1 torch.Size([64, 256, 1, 1]) torch.float32\n",
      "layer1.1.conv2 torch.Size([64, 64, 3, 3]) torch.float32\n",
      "layer1.1.conv3 torch.Size([256, 64, 1, 1]) torch.float32\n",
      "layer1.2.conv1 torch.Size([64, 256, 1, 1]) torch.float32\n",
      "layer1.2.conv2 torch.Size([64, 64, 3, 3]) torch.float32\n",
      "layer1.2.conv3 torch.Size([256, 64, 1, 1]) torch.float32\n",
      "layer2.0.conv1 torch.Size([128, 256, 1, 1]) torch.float32\n",
      "layer2.0.conv2 torch.Size([128, 128, 3, 3]) torch.float32\n",
      "layer2.0.conv3 torch.Size([512, 128, 1, 1]) torch.float32\n",
      "layer2.0.downsample.0 torch.Size([512, 256, 1, 1]) torch.float32\n",
      "layer2.1.conv1 torch.Size([128, 512, 1, 1]) torch.float32\n",
      "layer2.1.conv2 torch.Size([128, 128, 3, 3]) torch.float32\n",
      "layer2.1.conv3 torch.Size([512, 128, 1, 1]) torch.float32\n",
      "layer2.2.conv1 torch.Size([128, 512, 1, 1]) torch.float32\n",
      "layer2.2.conv2 torch.Size([128, 128, 3, 3]) torch.float32\n",
      "layer2.2.conv3 torch.Size([512, 128, 1, 1]) torch.float32\n",
      "layer2.3.conv1 torch.Size([128, 512, 1, 1]) torch.float32\n",
      "layer2.3.conv2 torch.Size([128, 128, 3, 3]) torch.float32\n",
      "layer2.3.conv3 torch.Size([512, 128, 1, 1]) torch.float32\n",
      "layer3.0.conv1 torch.Size([256, 512, 1, 1]) torch.float32\n",
      "layer3.0.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.0.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.0.downsample.0 torch.Size([1024, 512, 1, 1]) torch.float32\n",
      "layer3.1.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.1.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.1.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.2.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.2.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.2.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.3.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.3.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.3.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.4.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.4.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.4.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.5.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.5.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.5.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer4.0.conv1 torch.Size([512, 1024, 1, 1]) torch.float32\n",
      "layer4.0.conv2 torch.Size([512, 512, 3, 3]) torch.float32\n",
      "layer4.0.conv3 torch.Size([2048, 512, 1, 1]) torch.float32\n",
      "layer4.0.downsample.0 torch.Size([2048, 1024, 1, 1]) torch.float32\n",
      "layer4.1.conv1 torch.Size([512, 2048, 1, 1]) torch.float32\n",
      "layer4.1.conv2 torch.Size([512, 512, 3, 3]) torch.float32\n",
      "layer4.1.conv3 torch.Size([2048, 512, 1, 1]) torch.float32\n",
      "layer4.2.conv1 torch.Size([512, 2048, 1, 1]) torch.float32\n",
      "layer4.2.conv2 torch.Size([512, 512, 3, 3]) torch.float32\n",
      "layer4.2.conv3 torch.Size([2048, 512, 1, 1]) torch.float32\n",
      "OrderedDict([('conv1', [64, 3, 7, 7]), ('layer1.0.conv1', [64, 64, 1, 1]), ('layer1.0.conv2', [64, 64, 3, 3]), ('layer1.0.conv3', [256, 64, 1, 1]), ('layer1.0.downsample.0', [256, 64, 1, 1]), ('layer1.1.conv1', [64, 256, 1, 1]), ('layer1.1.conv2', [64, 64, 3, 3]), ('layer1.1.conv3', [256, 64, 1, 1]), ('layer1.2.conv1', [64, 256, 1, 1]), ('layer1.2.conv2', [64, 64, 3, 3]), ('layer1.2.conv3', [256, 64, 1, 1]), ('layer2.0.conv1', [128, 256, 1, 1]), ('layer2.0.conv2', [128, 128, 3, 3]), ('layer2.0.conv3', [512, 128, 1, 1]), ('layer2.0.downsample.0', [512, 256, 1, 1]), ('layer2.1.conv1', [128, 512, 1, 1]), ('layer2.1.conv2', [128, 128, 3, 3]), ('layer2.1.conv3', [512, 128, 1, 1]), ('layer2.2.conv1', [128, 512, 1, 1]), ('layer2.2.conv2', [128, 128, 3, 3]), ('layer2.2.conv3', [512, 128, 1, 1]), ('layer2.3.conv1', [128, 512, 1, 1]), ('layer2.3.conv2', [128, 128, 3, 3]), ('layer2.3.conv3', [512, 128, 1, 1]), ('layer3.0.conv1', [256, 512, 1, 1]), ('layer3.0.conv2', [256, 256, 3, 3]), ('layer3.0.conv3', [1024, 256, 1, 1]), ('layer3.0.downsample.0', [1024, 512, 1, 1]), ('layer3.1.conv1', [256, 1024, 1, 1]), ('layer3.1.conv2', [256, 256, 3, 3]), ('layer3.1.conv3', [1024, 256, 1, 1]), ('layer3.2.conv1', [256, 1024, 1, 1]), ('layer3.2.conv2', [256, 256, 3, 3]), ('layer3.2.conv3', [1024, 256, 1, 1]), ('layer3.3.conv1', [256, 1024, 1, 1]), ('layer3.3.conv2', [256, 256, 3, 3]), ('layer3.3.conv3', [1024, 256, 1, 1]), ('layer3.4.conv1', [256, 1024, 1, 1]), ('layer3.4.conv2', [256, 256, 3, 3]), ('layer3.4.conv3', [1024, 256, 1, 1]), ('layer3.5.conv1', [256, 1024, 1, 1]), ('layer3.5.conv2', [256, 256, 3, 3]), ('layer3.5.conv3', [1024, 256, 1, 1]), ('layer4.0.conv1', [512, 1024, 1, 1]), ('layer4.0.conv2', [512, 512, 3, 3]), ('layer4.0.conv3', [2048, 512, 1, 1]), ('layer4.0.downsample.0', [2048, 1024, 1, 1]), ('layer4.1.conv1', [512, 2048, 1, 1]), ('layer4.1.conv2', [512, 512, 3, 3]), ('layer4.1.conv3', [2048, 512, 1, 1]), ('layer4.2.conv1', [512, 2048, 1, 1]), ('layer4.2.conv2', [512, 512, 3, 3]), ('layer4.2.conv3', [2048, 512, 1, 1])])\n"
     ]
    }
   ],
   "source": [
    "# define resnet50\n",
    "model = models.resnet50(pretrained=False)\n",
    "fc_in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_in_features, 10)\n",
    "\n",
    "# random input\n",
    "random_input = np.random.randint(low=0, high=256, size=(28, 28), dtype=np.uint8)\n",
    "random_input = transform(random_input)\n",
    "y = torch.from_numpy(np.random.randint(low=0, high=10, size=(1), dtype=np.int64))\n",
    "\n",
    "# optimizer \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# forward pass\n",
    "model.train()\n",
    "logits = model(random_input)\n",
    "\n",
    "# backward pass\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, y)\n",
    "print(type(loss), loss.shape, loss.dtype, loss.item())\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "param_gradients_shape = collections.OrderedDict()\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "        param_gradients_shape[name] = np.array(layer.weight.grad.shape).tolist()\n",
    "        print(name, layer.weight.grad.shape, layer.weight.grad.dtype)\n",
    "optimizer.step()\n",
    "\n",
    "print(param_gradients_shape)\n",
    "\n",
    "with open(os.path.join(attack_with_NN_results_dir, \"param_gradients_shape.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(param_gradients_shape, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record hidden layer features and gradients in one forward pass and one backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 3, 224, 224]) torch.float32\n",
      "<class 'torch.Tensor'> torch.Size([1]) torch.int64\n",
      "\n",
      "conv1 <class 'torch.Tensor'> torch.Size([64, 112, 112]) torch.float32\n",
      "layer1.0.conv1 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.0.conv2 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.0.conv3 <class 'torch.Tensor'> torch.Size([256, 56, 56]) torch.float32\n",
      "layer1.0.downsample.0 <class 'torch.Tensor'> torch.Size([256, 56, 56]) torch.float32\n",
      "layer1.1.conv1 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.1.conv2 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.1.conv3 <class 'torch.Tensor'> torch.Size([256, 56, 56]) torch.float32\n",
      "layer1.2.conv1 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.2.conv2 <class 'torch.Tensor'> torch.Size([64, 56, 56]) torch.float32\n",
      "layer1.2.conv3 <class 'torch.Tensor'> torch.Size([256, 56, 56]) torch.float32\n",
      "layer2.0.conv1 <class 'torch.Tensor'> torch.Size([128, 56, 56]) torch.float32\n",
      "layer2.0.conv2 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.0.conv3 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer2.0.downsample.0 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer2.1.conv1 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.1.conv2 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.1.conv3 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer2.2.conv1 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.2.conv2 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.2.conv3 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer2.3.conv1 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.3.conv2 <class 'torch.Tensor'> torch.Size([128, 28, 28]) torch.float32\n",
      "layer2.3.conv3 <class 'torch.Tensor'> torch.Size([512, 28, 28]) torch.float32\n",
      "layer3.0.conv1 <class 'torch.Tensor'> torch.Size([256, 28, 28]) torch.float32\n",
      "layer3.0.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.0.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.0.downsample.0 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.1.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.1.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.1.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.2.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.2.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.2.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.3.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.3.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.3.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.4.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.4.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.4.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer3.5.conv1 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.5.conv2 <class 'torch.Tensor'> torch.Size([256, 14, 14]) torch.float32\n",
      "layer3.5.conv3 <class 'torch.Tensor'> torch.Size([1024, 14, 14]) torch.float32\n",
      "layer4.0.conv1 <class 'torch.Tensor'> torch.Size([512, 14, 14]) torch.float32\n",
      "layer4.0.conv2 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.0.conv3 <class 'torch.Tensor'> torch.Size([2048, 7, 7]) torch.float32\n",
      "layer4.0.downsample.0 <class 'torch.Tensor'> torch.Size([2048, 7, 7]) torch.float32\n",
      "layer4.1.conv1 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.1.conv2 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.1.conv3 <class 'torch.Tensor'> torch.Size([2048, 7, 7]) torch.float32\n",
      "layer4.2.conv1 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.2.conv2 <class 'torch.Tensor'> torch.Size([512, 7, 7]) torch.float32\n",
      "layer4.2.conv3 <class 'torch.Tensor'> torch.Size([2048, 7, 7]) torch.float32\n",
      "\n",
      "<class 'torch.Tensor'> torch.Size([]) torch.float32 3.363617420196533\n",
      "\n",
      "conv1 torch.Size([64, 3, 7, 7]) torch.float32\n",
      "layer1.0.conv1 torch.Size([64, 64, 1, 1]) torch.float32\n",
      "layer1.0.conv2 torch.Size([64, 64, 3, 3]) torch.float32\n",
      "layer1.0.conv3 torch.Size([256, 64, 1, 1]) torch.float32\n",
      "layer1.0.downsample.0 torch.Size([256, 64, 1, 1]) torch.float32\n",
      "layer1.1.conv1 torch.Size([64, 256, 1, 1]) torch.float32\n",
      "layer1.1.conv2 torch.Size([64, 64, 3, 3]) torch.float32\n",
      "layer1.1.conv3 torch.Size([256, 64, 1, 1]) torch.float32\n",
      "layer1.2.conv1 torch.Size([64, 256, 1, 1]) torch.float32\n",
      "layer1.2.conv2 torch.Size([64, 64, 3, 3]) torch.float32\n",
      "layer1.2.conv3 torch.Size([256, 64, 1, 1]) torch.float32\n",
      "layer2.0.conv1 torch.Size([128, 256, 1, 1]) torch.float32\n",
      "layer2.0.conv2 torch.Size([128, 128, 3, 3]) torch.float32\n",
      "layer2.0.conv3 torch.Size([512, 128, 1, 1]) torch.float32\n",
      "layer2.0.downsample.0 torch.Size([512, 256, 1, 1]) torch.float32\n",
      "layer2.1.conv1 torch.Size([128, 512, 1, 1]) torch.float32\n",
      "layer2.1.conv2 torch.Size([128, 128, 3, 3]) torch.float32\n",
      "layer2.1.conv3 torch.Size([512, 128, 1, 1]) torch.float32\n",
      "layer2.2.conv1 torch.Size([128, 512, 1, 1]) torch.float32\n",
      "layer2.2.conv2 torch.Size([128, 128, 3, 3]) torch.float32\n",
      "layer2.2.conv3 torch.Size([512, 128, 1, 1]) torch.float32\n",
      "layer2.3.conv1 torch.Size([128, 512, 1, 1]) torch.float32\n",
      "layer2.3.conv2 torch.Size([128, 128, 3, 3]) torch.float32\n",
      "layer2.3.conv3 torch.Size([512, 128, 1, 1]) torch.float32\n",
      "layer3.0.conv1 torch.Size([256, 512, 1, 1]) torch.float32\n",
      "layer3.0.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.0.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.0.downsample.0 torch.Size([1024, 512, 1, 1]) torch.float32\n",
      "layer3.1.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.1.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.1.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.2.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.2.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.2.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.3.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.3.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.3.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.4.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.4.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.4.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer3.5.conv1 torch.Size([256, 1024, 1, 1]) torch.float32\n",
      "layer3.5.conv2 torch.Size([256, 256, 3, 3]) torch.float32\n",
      "layer3.5.conv3 torch.Size([1024, 256, 1, 1]) torch.float32\n",
      "layer4.0.conv1 torch.Size([512, 1024, 1, 1]) torch.float32\n",
      "layer4.0.conv2 torch.Size([512, 512, 3, 3]) torch.float32\n",
      "layer4.0.conv3 torch.Size([2048, 512, 1, 1]) torch.float32\n",
      "layer4.0.downsample.0 torch.Size([2048, 1024, 1, 1]) torch.float32\n",
      "layer4.1.conv1 torch.Size([512, 2048, 1, 1]) torch.float32\n",
      "layer4.1.conv2 torch.Size([512, 512, 3, 3]) torch.float32\n",
      "layer4.1.conv3 torch.Size([2048, 512, 1, 1]) torch.float32\n",
      "layer4.2.conv1 torch.Size([512, 2048, 1, 1]) torch.float32\n",
      "layer4.2.conv2 torch.Size([512, 512, 3, 3]) torch.float32\n",
      "layer4.2.conv3 torch.Size([2048, 512, 1, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "class HiddenLayerFeatures:\n",
    "    \"\"\"\n",
    "    one object for each data point (x, y).\n",
    "    \n",
    "    If there are 2*N data points (defender+reserve), \n",
    "    then 2*N such objects need to be instantiated. \n",
    "    \"\"\"\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "        self.data = {}\n",
    "        \n",
    "    def get_hook(self, name):\n",
    "        def hook(model, input, output):\n",
    "            # .squeeze(dim=0) because of batch_size = 1\n",
    "            self.data[name] = output.detach().squeeze(dim=0)\n",
    "        return hook\n",
    "\n",
    "\n",
    "# random input\n",
    "random_input = np.random.randint(low=0, high=256, size=(28, 28), dtype=np.uint8)\n",
    "random_input = transform(random_input)\n",
    "print(type(random_input), random_input.shape, random_input.dtype)\n",
    "y = torch.from_numpy(np.random.randint(low=0, high=10, size=(1), dtype=np.int64))\n",
    "print(type(y), y.shape, y.dtype)\n",
    "print()\n",
    "\n",
    "# define resnet50\n",
    "model = models.resnet50(pretrained=False)\n",
    "fc_in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(fc_in_features, 10)\n",
    "\n",
    "# optimizer \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# set up forward_hooks\n",
    "hidden_layer_features = HiddenLayerFeatures(0)\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "        layer.register_forward_hook(hidden_layer_features.get_hook(name))\n",
    "\n",
    "\n",
    "# forward pass\n",
    "model.train()\n",
    "logits = model(random_input)\n",
    "\n",
    "# get hidden layer features\n",
    "for k in hidden_layer_features.data.keys():\n",
    "    print(k, type(hidden_layer_features.data[k]), hidden_layer_features.data[k].shape, \n",
    "          hidden_layer_features.data[k].dtype)\n",
    "\n",
    "print()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, y)\n",
    "print(type(loss), loss.shape, loss.dtype, loss.item())\n",
    "\n",
    "print()\n",
    "\n",
    "# backward pass\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
    "        print(name, layer.weight.grad.shape, layer.weight.grad.dtype)\n",
    "\n",
    "#optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ocr",
   "language": "python",
   "name": "venv_ocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
